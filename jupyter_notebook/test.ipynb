{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/hiroki/python_projects/LightRAG\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in ./venv/lib/python3.11/site-packages (from lightrag-hku==1.2.1) (3.11.12)\n",
      "Requirement already satisfied: configparser in ./venv/lib/python3.11/site-packages (from lightrag-hku==1.2.1) (7.1.0)\n",
      "Requirement already satisfied: future in ./venv/lib/python3.11/site-packages (from lightrag-hku==1.2.1) (1.0.0)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.11/site-packages (from lightrag-hku==1.2.1) (1.26.4)\n",
      "Requirement already satisfied: pipmaster in ./venv/lib/python3.11/site-packages (from lightrag-hku==1.2.1) (0.4.0)\n",
      "Requirement already satisfied: pydantic in ./venv/lib/python3.11/site-packages (from lightrag-hku==1.2.1) (2.10.6)\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.11/site-packages (from lightrag-hku==1.2.1) (1.0.1)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.11/site-packages (from lightrag-hku==1.2.1) (65.5.0)\n",
      "Requirement already satisfied: tenacity in ./venv/lib/python3.11/site-packages (from lightrag-hku==1.2.1) (9.0.0)\n",
      "Requirement already satisfied: tiktoken in ./venv/lib/python3.11/site-packages (from lightrag-hku==1.2.1) (0.9.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv/lib/python3.11/site-packages (from aiohttp->lightrag-hku==1.2.1) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.11/site-packages (from aiohttp->lightrag-hku==1.2.1) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.11/site-packages (from aiohttp->lightrag-hku==1.2.1) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.11/site-packages (from aiohttp->lightrag-hku==1.2.1) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.11/site-packages (from aiohttp->lightrag-hku==1.2.1) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.11/site-packages (from aiohttp->lightrag-hku==1.2.1) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.11/site-packages (from aiohttp->lightrag-hku==1.2.1) (1.18.3)\n",
      "Requirement already satisfied: ascii-colors in ./venv/lib/python3.11/site-packages (from pipmaster->lightrag-hku==1.2.1) (0.5.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.11/site-packages (from pydantic->lightrag-hku==1.2.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./venv/lib/python3.11/site-packages (from pydantic->lightrag-hku==1.2.1) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in ./venv/lib/python3.11/site-packages (from pydantic->lightrag-hku==1.2.1) (4.12.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.11/site-packages (from tiktoken->lightrag-hku==1.2.1) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./venv/lib/python3.11/site-packages (from tiktoken->lightrag-hku==1.2.1) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->lightrag-hku==1.2.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->lightrag-hku==1.2.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->lightrag-hku==1.2.1) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->lightrag-hku==1.2.1) (2025.1.31)\n",
      "Building wheels for collected packages: lightrag-hku\n",
      "  Building editable for lightrag-hku (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lightrag-hku: filename=lightrag_hku-1.2.1-0.editable-py3-none-any.whl size=19650 sha256=c82ca2ecba6441d0edc803270da0a27f00f00c44b79f6c26166a2dc12d367ea0\n",
      "  Stored in directory: /private/var/folders/hq/c4j70k6n0lzgk7tskjf3yc3h0000gn/T/pip-ephem-wheel-cache-v5spw6mi/wheels/d4/6a/cb/a90747dc4371c4a29cbfff8f586067751bfa826cd4ed168aef\n",
      "Successfully built lightrag-hku\n",
      "Installing collected packages: lightrag-hku\n",
      "  Attempting uninstall: lightrag-hku\n",
      "    Found existing installation: lightrag-hku 1.2.1\n",
      "    Uninstalling lightrag-hku-1.2.1:\n",
      "      Successfully uninstalled lightrag-hku-1.2.1\n",
      "Successfully installed lightrag-hku-1.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest_asyncio in ./venv/lib/python3.11/site-packages (1.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nest_asyncio\n",
    "import nest_asyncio \n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChordProgression6\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from os.path import join, dirname\n",
    "import os\n",
    "load_dotenv(verbose=True)\n",
    "\n",
    "dotenv_path = join('/Users/hiroki/python_projects/dev_lightRAG', '.env')\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "WORKING_DIR = os.environ.get(\"WORKING_DIR\")\n",
    "\n",
    "print(WORKING_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dotenv.main:Python-dotenv could not find configuration file .env.\n",
      "INFO:lightrag:Logger initialized for working directory: ChordProgression6\n",
      "DEBUG:lightrag:LightRAG init with param:\n",
      "  working_dir = ChordProgression6,\n",
      "  kv_storage = JsonKVStorage,\n",
      "  vector_storage = NanoVectorDBStorage,\n",
      "  graph_storage = NetworkXStorage,\n",
      "  doc_status_storage = JsonDocStatusStorage,\n",
      "  log_level = DEBUG,\n",
      "  log_file_path = /Users/hiroki/python_projects/LightRAG/lightrag.log,\n",
      "  entity_extract_max_gleaning = 1,\n",
      "  entity_summary_to_max_tokens = 500,\n",
      "  chunk_token_size = 1200,\n",
      "  chunk_overlap_token_size = 100,\n",
      "  tiktoken_model_name = gpt-4o-mini,\n",
      "  chunking_func = <function chunking_by_token_size at 0x10ef1c360>,\n",
      "  node_embedding_algorithm = node2vec,\n",
      "  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},\n",
      "  embedding_func = {'embedding_dim': 1536, 'max_token_size': 8192, 'func': <function openai_embed at 0x11292fce0>},\n",
      "  embedding_batch_num = 32,\n",
      "  embedding_func_max_async = 16,\n",
      "  embedding_cache_config = {'enabled': False, 'similarity_threshold': 0.95, 'use_llm_check': False},\n",
      "  llm_model_func = <function gpt_4o_mini_complete at 0x11292f740>,\n",
      "  llm_model_name = gpt-4o-mini,\n",
      "  llm_model_max_token_size = 32768,\n",
      "  llm_model_max_async = 16,\n",
      "  llm_model_kwargs = {},\n",
      "  vector_db_storage_cls_kwargs = {'cosine_better_than_threshold': 0.2},\n",
      "  namespace_prefix = ,\n",
      "  enable_llm_cache = True,\n",
      "  enable_llm_cache_for_entity_extract = True,\n",
      "  max_parallel_insert = 20,\n",
      "  addon_params = {},\n",
      "  auto_manage_storages_states = True,\n",
      "  convert_response_to_json_func = <function convert_response_to_json at 0x10eb55f80>,\n",
      "  cosine_better_than_threshold = 0.2,\n",
      "  _storages_status = StoragesStatus.NOT_CREATED\n",
      "\n",
      "INFO:lightrag:Load KV llm_response_cache with 6 data\n",
      "INFO:lightrag:Load KV full_docs with 1 data\n",
      "INFO:lightrag:Load KV text_chunks with 1 data\n",
      "INFO:lightrag:Loaded graph from ChordProgression6/graph_chunk_entity_relation.graphml with 6 nodes, 14 edges\n",
      "INFO:nano-vectordb:Load (6, 1536) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': 'ChordProgression6/vdb_entities.json'} 6 data\n",
      "INFO:nano-vectordb:Load (14, 1536) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': 'ChordProgression6/vdb_relationships.json'} 14 data\n",
      "INFO:nano-vectordb:Load (1, 1536) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': 'ChordProgression6/vdb_chunks.json'} 1 data\n",
      "INFO:lightrag:Loaded document status storage with 1 records\n",
      "DEBUG:lightrag:Initialized Storages\n",
      "DEBUG:lightrag:Finalized Storages\n",
      "INFO:lightrag:No new unique documents were found.\n",
      "INFO:lightrag:All documents have been processed or are duplicates\n",
      "INFO:lightrag:Non-embedding cached hit(mode:naive type:query)\n",
      "INFO:lightrag:Non-embedding cached hit(mode:hybrid type:query)\n",
      "INFO:lightrag:Non-embedding cached missed(mode:mix type:query)\n",
      "INFO:lightrag:Non-embedding cached hit(mode:mix type:keywords)\n",
      "INFO:lightrag:Query nodes: Intravenous, Fluid administration, Medication, Monitoring, Patient recovery, top_k: 60, cosine: 0.2\n",
      "INFO:lightrag:Query edges: IV therapy, Medical procedures, Post-treatment care, top_k: 60, cosine: 0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate data. Not added.\n",
      "=== mode: naive ===\n",
      "Based on the provided Document Chunks, here are the sequences that follow IV:\n",
      "\n",
      "### Sequences Following IV\n",
      "\n",
      "1. **IV is followed by:**\n",
      "   - V, I (found in the chunk \"IV | I | is followed by | V | VI\")\n",
      "   - III, VI (found in the chunk \"IV | V | is followed by | III | VI\")\n",
      "   - VI, V (found in the chunk \"IV | I | is followed by | VI | V\")\n",
      "\n",
      "These sequences indicate that IV can lead to various elements, specifically V, I, III, VI, and V, depending on the context.\n",
      "Duplicate data. Not added.\n",
      "=== mode: hybrid ===\n",
      "### Events Following IV\n",
      "\n",
      "IV is followed by several key events in the sequence:\n",
      "\n",
      "1. **V**: IV is directly followed by V, establishing a crucial connection within the sequence.\n",
      "2. **VI**: IV is also followed by VI, reinforcing its role in the overall sequence relationship.\n",
      "3. **III**: Additionally, III follows IV, showing another aspect of the interconnected events.\n",
      "\n",
      "Overall, IV serves as an intermediary event linking multiple subsequent events (V, VI, and III) in the sequence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:lightrag:Truncate relations from 14 to 14 (max tokens:4000)\n",
      "DEBUG:lightrag:Truncate chunks from 1 to 1 (max tokens:4000)\n",
      "DEBUG:lightrag:Truncate entities from 6 to 6 (max tokens:4000)\n",
      "INFO:lightrag:Local query uses 6 entites, 14 relations, 1 chunks\n",
      "DEBUG:lightrag:Truncate chunks from 1 to 1 (max tokens:4000)\n",
      "DEBUG:lightrag:Truncate entities from 6 to 6 (max tokens:4000)\n",
      "INFO:lightrag:Global query uses 6 entites, 7 relations, 1 chunks\n",
      "DEBUG:lightrag:Truncate chunks from 1 to 1 (max tokens:4000)\n",
      "DEBUG:lightrag:[mix_kg_vector_query]Prompt Tokens: 2427\n",
      "DEBUG:lightrag:===== Sending Query to LLM =====\n",
      "DEBUG:lightrag:Model: gpt-4o-mini   Base URL: None\n",
      "DEBUG:lightrag:Additional kwargs: {'stream': False}\n",
      "INFO:lightrag:Non-embedding cached hit(mode:local type:query)\n",
      "INFO:lightrag:Non-embedding cached hit(mode:global type:query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data added to JSON!\n",
      "=== mode: mix ===\n",
      "### Sequential Relationships Following IV\n",
      "\n",
      "In the context of the events connected with IV, the following relationships can be highlighted:\n",
      "\n",
      "- **V follows IV**: IV is followed directly by V, indicating a continuation in the sequence.\n",
      "- **VI follows IV**: There is also a sequential relationship where VI comes after IV, reinforcing its role in the overall sequence.\n",
      "- **III follows IV**: Moreover, III is indicated to follow IV as well, contributing to the interconnected sequence of events.\n",
      "\n",
      "### Summary of Connections\n",
      "\n",
      "These connections illustrate that IV serves as a critical junction in this sequence, linking to multiple subsequent elements (V, VI, and III). Each of these follow-ups maintains an essential part of the overall structure within the series of events.\n",
      "\n",
      "### References\n",
      "\n",
      "1. [KG] \"IV is followed by V illustrating the connectivity of the sequence.\"\n",
      "2. [KG] \"IV is followed by VI, reinforcing its role in the sequence relationship.\"\n",
      "3. [KG] \"III is followed by IV, establishing a direct sequence connection.\"\n",
      "Duplicate data. Not added.\n",
      "=== mode: local ===\n",
      "### Relationship After IV\n",
      "\n",
      "In the sequence, IV is followed by both V and VI:\n",
      "\n",
      "- **V**: IV is directly followed by V, establishing a clear connection in the sequence. \n",
      "- **VI**: Additionally, IV is followed by VI, reinforcing its role in the overall sequence of events.\n",
      "\n",
      "Thus, following IV, we have V and VI as subsequent elements in the sequence.\n",
      "Duplicate data. Not added.\n",
      "=== mode: global ===\n",
      "### Sequence Following IV\n",
      "\n",
      "In the sequence of events, IV is followed by two entities:\n",
      "\n",
      "1. **V**: IV directly connects to V, showcasing an integral part of the sequence.\n",
      "2. **VI**: IV is followed by VI, reinforcing its role in the overall sequence of events.\n",
      "\n",
      "Both relationships demonstrate the sequential connectivity that IV maintains with subsequent elements in the system.\n"
     ]
    }
   ],
   "source": [
    "from os.path import join, dirname\n",
    "import os\n",
    "from app import LightRAGHandler\n",
    "from dotenv import load_dotenv\n",
    "from os.path import join, dirname\n",
    "\n",
    "load_dotenv(verbose=True)\n",
    "\n",
    "#dotenv_path = join(dirname(__file__), '.env')\n",
    "dotenv_path = join('/Users/hiroki/python_projects/dev_lightRAG', '.env')\n",
    "\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "WORKING_DIR = os.environ.get(\"WORKING_DIR\")\n",
    "\n",
    "\n",
    "# filepath = \"./docs/chord_progress/var1.txt\"\n",
    "filepath = \"../dev_lightRAG/docs/chord_progress/var1.txt\"\n",
    "\n",
    "handler = LightRAGHandler()\n",
    "handler.text_insert(filepath)\n",
    "\n",
    "\n",
    "# # Perform naive search\n",
    "# mode=\"naive\"\n",
    "# # Perform local search\n",
    "# mode=\"local\"\n",
    "# # Perform global search\n",
    "# mode=\"global\"\n",
    "# # Perform hybrid search\n",
    "# mode=\"hybrid\"\n",
    "# # Mix mode Integrates knowledge graph and vector retrieval.\n",
    "# mode=\"mix\"\n",
    "\n",
    "mode_list = [\"naive\", \"hybrid\", \"mix\", \"local\" , \"global\"]\n",
    "\n",
    "for mode in mode_list:\n",
    "    query = 'What is followed after IV'\n",
    "    content = handler.rag_query(query=query, mode=mode)\n",
    "    print(\"=== mode: {} ===\".format(mode ) )\n",
    "    print(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
